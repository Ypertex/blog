<!doctype html>
<html lang="en">

<head>
    <meta name="generator" content="Hugo 0.141.0">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">


<link rel="stylesheet" href="/ypertex.css">
<link rel="stylesheet"
    href="https://fonts.googleapis.com/css?family=Montserrat+Alternates:700,700i|Montserrat:400,400i,700,700i&display=swap">
<link rel="stylesheet"
    href="https://maxst.icons8.com/vue-static/landings/line-awesome/line-awesome/1.3.0/css/line-awesome.min.css">
<title>The True Challenge of the AI Alignment Problem · Ypertex Blog</title>
<link rel="apple-touch-icon" sizes="57x57" href="/apple-touch-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="/apple-touch-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="/apple-touch-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="/apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="/apple-touch-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="/apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="/apple-touch-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="/apple-touch-icon-152x152.png">
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon-180x180.png">
<link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
<link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/favicon-96x96.png" sizes="96x96">
<link rel="icon" type="image/png" href="/android-chrome-192x192.png" sizes="192x192">
<meta name="msapplication-square70x70logo" content="/smalltile.png" />
<meta name="msapplication-square150x150logo" content="/mediumtile.png" />
<meta name="msapplication-wide310x150logo" content="/widetile.png" />
<meta name="msapplication-square310x310logo" content="/largetile.png" />
<meta property="og:logo" content="https://blog.ypertex.com//android-chrome-192x192.png">
<meta property="og:url" content="https://blog.ypertex.com/articles/alignment-by-the-unaligned/">
  <meta property="og:site_name" content="Ypertex Blog">
  <meta property="og:title" content="The True Challenge of the AI Alignment Problem">
  <meta property="og:description" content="AI is a big topic these days. One reason for this is the fear of AIs acting against human values, potentially causing severe consequences. However, there’s an even bigger challenge than aligning AIs: Let’s look in the mirror.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="articles">
    <meta property="article:published_time" content="2023-04-04T00:00:00+00:00">
    <meta property="article:modified_time" content="2023-04-04T00:00:00+00:00">
    <meta property="article:tag" content="AI">
    <meta property="article:tag" content="Future">
    <meta property="article:tag" content="Strategy">
    <meta property="og:image" content="https://res.cloudinary.com/ypertex/image/upload/c_fill,dpr_auto,f_auto,g_auto,h_630,q_auto,w_1200/16dfe5a0-5ad3-4030-9357-d68789922e49">


<meta property="article:author" content="Michael Schmidle" />

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="https://res.cloudinary.com/ypertex/image/upload/c_fill,dpr_auto,f_auto,g_auto,h_630,q_auto,w_1200/16dfe5a0-5ad3-4030-9357-d68789922e49">
  <meta name="twitter:title" content="The True Challenge of the AI Alignment Problem">
  <meta name="twitter:description" content="AI is a big topic these days. One reason for this is the fear of AIs acting against human values, potentially causing severe consequences. However, there’s an even bigger challenge than aligning AIs: Let’s look in the mirror.">


</head>

<body>
    <header>
    <nav class="navbar">
        <div class="container">
            <a class="navbar-brand"
                href="/"><svg width="100%" height="100%" viewBox="0 0 440 176" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" xmlns:serif="http://www.serif.com/" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:2;">
    <g transform="matrix(1,0,0,1,-2574,-792)">
        <g id="Unprotected-primary-color-logogram-on-transparent-background" serif:id="Unprotected primary color logogram on transparent background" transform="matrix(1.12719,0,0,0.885774,2612.5,797.543)">
            <rect x="-34.159" y="-6.258" width="390.352" height="198.696" style="fill:none;"/>
            <clipPath id="_clip1">
                <rect x="-34.159" y="-6.258" width="390.352" height="198.696"/>
            </clipPath>
            <g clip-path="url(#_clip1)">
                <g transform="matrix(3.69565,0,0,4.16217,-240.2,-272.956)">
                    <g transform="matrix(0.105625,-6.62507e-18,5.86335e-18,0.119347,45.1899,52.1434)">
                        <path d="M100,500L300,300L100,100L167.274,100C252.258,100 333.761,133.757 393.857,193.846C397.723,197.712 400,199.988 400,199.988L500,99.976L699.976,100L800,200.024L900,100L1100,100L900,300L1100,500L1032.74,500C947.747,500 866.238,466.238 806.141,406.141C802.276,402.276 800,400 800,400L700,500L500,500L700,300L600,200.024L300,500L100,500Z" style="fill:rgb(0,170,255);"/>
                    </g>
                    <g transform="matrix(0.105625,0,0,0.119347,45.1899,40.2116)">
                        <path d="M500,599.976L900,199.976L700,199.953L300,599.976L500,599.976Z" style="fill:rgb(14,17,18);fill-opacity:0.2;"/>
                    </g>
                </g>
            </g>
        </g>
    </g>
</svg>
</a>
            <button type="button" data-toggle="collapse" data-target="#menuHeader" aria-controls="menu.header"
                aria-expanded="false" aria-label="Toggle navigation">
                <i class="las la-bars"></i>
            </button>
            <div class="navbar-collapse collapse" id="menuHeader">
                <div class="navbar-nav mr-md-auto">
                    
                    
                    <a href="/articles/"
                        class="nav-item nav-link active">Articles</a>
                    
                    <a href="/tags/"
                        class="nav-item nav-link">Tags</a>
                    
                </div>
                <div class="navbar-nav">
                    <hr>
                    
                    <a href="https://www.linkedin.com/in/MichaelSchmidle" class="nav-item nav-link" title="LinkedIn"><i class="lab la-linkedin-in"></i><span
                            class="d-md-none"> LinkedIn</span></a>
                    
                    <a href="https://github.com/MichaelSchmidle/" class="nav-item nav-link" title="GitHub"><i class="lab la-github"></i><span
                            class="d-md-none"> GitHub</span></a>
                    
                    <a href="https://soundcloud.com/michaelschmidle/" class="nav-item nav-link" title="SoundCloud"><i class="lab la-soundcloud"></i><span
                            class="d-md-none"> SoundCloud</span></a>
                    
                    <a href="/index.xml" class="nav-item nav-link" title="RSS"><i
                            class="las la-rss"></i><span class="d-md-none"> RSS</span></a>
                </div>
            </div>
        </div>
    </nav>
</header>
    <main>
        
<section class="jumbotron">
    <div class="container">
        <h1>The True Challenge of the AI Alignment Problem</h1>
        <p class="text-muted mb-2"><small><i
            class="las la-upload"></i>&nbsp;Apr 4, 2023 · <i
            class="las la-stopwatch"></i>&nbsp;5min read</small></p>
        <p class="mb-2">
    
    <a href="/tags/ai/" class="badge badge-primary"><i class="las la-hashtag"></i>AI</a>
    
    <a href="/tags/future/" class="badge badge-primary"><i class="las la-hashtag"></i>Future</a>
    
    <a href="/tags/strategy/" class="badge badge-primary"><i class="las la-hashtag"></i>Strategy</a>
    
</p>
                
    </div>
</section>
<section class="yx-content container py-5">
    <div class="row">
        <div class="col-xl-8 col-lg-10 mx-auto">
            <p class="lead">AI is a big topic these days. One reason for this is the fear of AIs acting against human values, potentially causing severe consequences. However, there&rsquo;s an even bigger challenge than aligning AIs: Let&rsquo;s look in the mirror.</p>
                    
            <hr>
            <p>Today&rsquo;s Large Language Models (LLMs) like GPT seem to be close to the level of human intelligence already. If I use OpenAI&rsquo;s ChatGPT 3.5 or 4, I can have serious conversations about a wide range of topics with it.</p>
<p>Well, it&rsquo;s not really a conversation since I never get asked a question back by the AI. It&rsquo;s one-sided, to be honest. Additionally, there&rsquo;s a point when its limits become apparent: It starts to &ldquo;forget&rdquo; earlier context of the chat (due to its limited <a href="https://platform.openai.com/tokenizer">token size</a>). When continuity and consistency get broken, I&rsquo;m reminded that the intelligence is artificial.</p>
<blockquote>
<p>Overall, it <em>feels</em> like talking to a highly intelligent, yet pretty dement being.</p>
</blockquote>
<p>It takes some time though, to uncover inconsistency and failing continuity. I&rsquo;ve seen other humans feed short GPT-generated <em>intelligent</em> output into other AIs that turn text into <em>believable</em> audio or video. The combination of <em>intelligent and believable</em> in this context means that it takes me, a 44-year-old trained technology and strategy expert, intentional mental effort to identify it as what it is: artificial. If I&rsquo;m running on autopilot and don&rsquo;t pay attention, I&rsquo;ll buy it as real.</p>
<p>So, even with all current limitations of single AIs, there&rsquo;s reason for serious concern about the power that comes with Artificial Intelligences. (Yes, plural.)</p>
<figure>
    
    <picture>
        <source media="(min-width: 1200px)"
            srcset="https://res.cloudinary.com/ypertex/image/upload/ar_1.67,c_fill,dpr_auto,f_auto,g_auto,q_auto,w_1140/16dfe5a0-5ad3-4030-9357-d68789922e49">
        <source media="(min-width: 992px)"
            srcset="https://res.cloudinary.com/ypertex/image/upload/ar_1.67,c_fill,dpr_auto,f_auto,g_auto,q_auto,w_960/16dfe5a0-5ad3-4030-9357-d68789922e49">
        <source media="(min-width: 768px)"
            srcset="https://res.cloudinary.com/ypertex/image/upload/ar_1.67,c_fill,dpr_auto,f_auto,g_auto,q_auto,w_720/16dfe5a0-5ad3-4030-9357-d68789922e49">
        <source media="(min-width: 576px)"
            srcset="https://res.cloudinary.com/ypertex/image/upload/ar_1.67,c_fill,dpr_auto,f_auto,g_auto,q_auto,w_767/16dfe5a0-5ad3-4030-9357-d68789922e49">
        <img src="https://res.cloudinary.com/ypertex/image/upload/ar_1.67,c_fill,dpr_auto,f_auto,g_auto,q_auto,w_575/16dfe5a0-5ad3-4030-9357-d68789922e49"
            alt="">
    </picture>
    
    <figcaption>
        &ldquo;Visually engaging and thought-provoking image that represents the AI Alignment challenge and the complex nature of it.&rdquo; <span class="yx-attribution">Image:
            Midjourney, a text-to-image AI</span>
    </figcaption>
</figure>
<h2 id="a-matter-of-trust">A Matter of Trust&nbsp<a href="#a-matter-of-trust"
        class="heading">¶</a></h2><p>These concerns come from a simple fact: It&rsquo;s the first time in history of humankind that even experts don&rsquo;t know how a globally deployed technology <em>really</em> works. Usually, people who don&rsquo;t know just resort to trusting people who, in fact, do know. Yet in the case of today&rsquo;s Large Language Models, we don&rsquo;t know and can&rsquo;t even fall back to trusting anyone else&mdash;because literally <strong>nobody really knows</strong>.</p>
<p>That&rsquo;s where the AI Alignment comes in. If we can&rsquo;t know the inner workings or can&rsquo;t trust another human who knows, is there a way to implement at least some safeguards?</p>
<p>Sure. The theoretical solution is to align the thing that we don&rsquo;t understand with our values. In more practical terms, this means that both humans and machines put the same value on the same outcomes. For example, if humans put high value on their survival, machines will put equally high value on the humans&rsquo; survival. Shared core values will generate compatible intentions, and resulting outcomes will complement each other. In such a scenario, there&rsquo;s simply no need to fully understand the inner workings of that thing we don&rsquo;t understand.</p>
<p>There are a few challenges on the way of practically rolling out this solution, however:</p>
<p>First, how can we reliably implement shared core values in a machine that nobody really understands? That&rsquo;s a tricky one. Have we even defined to the letter what those core values would be?</p>
<p>Second, how do we overcome the overwhelming odds against full-time alignment? Consider this:</p>
<blockquote>
<p>A single AI that misaligns <em>only once</em> can trigger serious consequences. Humans on the other hand require <em>full-time</em> alignment to avoid any such situation.</p>
</blockquote>
<p>Hm, that&rsquo;s an impossible one. What&rsquo;s more probable: a single misalignment once&mdash;or eternal full alignment? You do the math.</p>
<p>That&rsquo;s why it&rsquo;s called AI Alignment <em>Problem</em>. But that&rsquo;s not even the biggest issue.</p>
<h2 id="the-true-challenge-unaligned-humans">The True Challenge: Unaligned Humans&nbsp<a href="#the-true-challenge-unaligned-humans"
        class="heading">¶</a></h2><p>Let&rsquo;s take a step back here and look at this from a historical point of view. Using the <a href="http://localhost:1313/articles/humanity-is-expecting-offspring/#evolution-of-intelligence">Cosmic Calendar</a> as a scale (that maps the time from the Big Bang until today onto a single calendar year), Columbus has discovered America just 1.2 seconds before midnight of December 31. On this scale, AI has been in development for the last 0.1 seconds of the Cosmic Calendar. In contrast, modern humans have evolved a whopping eight minutes before that.</p>
<p>In other words, trying to align natural intelligences (i.e., humans) is something we&rsquo;ve been practicing around four thousand times longer than we&rsquo;ve been trying to align artificial <em>and</em> natural ones. And, after all this time, I can state with a high degree of confidence: Natural intelligences are not yet aligned at all. Especially today, we can observe polarization (a synonym for misalignment) of human societies on every level. Throughout humankind as we live and breathe today, we still can&rsquo;t agree on a single thing of global relevance.</p>
<blockquote>
<p>If we haven&rsquo;t managed to align natural intelligences so far, how are we supposed to align natural and artificial intelligences?</p>
</blockquote>
<p>To make matters worse: So far, we&rsquo;ve failed at aligning <em>intelligences of our own kind</em>. Intelligences that&mdash;while we still don&rsquo;t fully comprehend them&mdash;are the most familiar to us.</p>
<h2 id="can-the-unaligned-earthlings-align-the-unaligned-alien">Can the Unaligned Earthlings Align the Unaligned Alien?&nbsp<a href="#can-the-unaligned-earthlings-align-the-unaligned-alien"
        class="heading">¶</a></h2><p>Being aligned as humans is the absolute prerequisite for solving the AI Alignment Problem. The big tech companies at the forefront of developing AI would have to be the first to be aligned. (Remember: We&rsquo;re talking about AIs, plural.)</p>
<p>Today, that&rsquo;s an impossibility due to the incentives not being in sync: Nobody gets rewarded for getting aligned. On the contrary, developing a competitive advantage and precisely not falling in line is what brings the biggest rewards. We cherish diversity and individuality in some way, shape, or form.</p>
<p>Being the inveterate optimist that I am, I believe that humankind will solve this problem. I also believe that we&rsquo;ll solve it in a way we can&rsquo;t imagine just yet. (It&rsquo;ll somehow involve synchronization of incentives, I can tell as much.) I see the great value in Large Language Models and hope that we&rsquo;ll be able to harness it at acceptable risks.</p>
<p>This article serves as <strong>a call to focus our work primarily at aligning ourselves</strong> in matters of upmost importance. It&rsquo;s the necessary step we need to take before all else.</p>
<h2 id="conclusion">Conclusion&nbsp<a href="#conclusion"
        class="heading">¶</a></h2><p>AIs are developed at neck-breaking speeds and achieve impressive levels of intelligence already today. The problem is: Nobody <em>really</em> knows how they work&mdash;and humankind has no experience dealing with globally deployed technologies that nobody really understands.</p>
<p>This article takes a stab at the proposed solution of AI Alignment. It shows the impracticability or even impossibility of the solution, at least as long as the human side of things is as misaligned as it currently is. Let&rsquo;s try to fix that first by taking a long, hard look at how our incentives are currently structured.</p>

            
        </div>
    </div>
</section>

<section class="bg-light py-5">
    <div class="container">
        <div class="row">
            <div class="col-xl-8 col-lg-10 mx-auto">
                <div class="yx-heading">About the Author</div>
<div class="media">
    <img
        src="https://res.cloudinary.com/ypertex/image/upload/ar_1,c_thumb,dpr_auto,f_auto,g_face,q_auto,w_128/people/michael-schmidle-2021-10"
        class="yx-avatar">
    <div class="media-body">
        <h4>Michael Schmidle</h4>
        <p>Founder of <a href="https://www.priomind.com/">PrioMind</a>. Start-up consultant, hobby music producer and blogger. Opinionated about technology, strategy, and leadership. In love with Mexico. This blog reflects my personal views.</p>

        <p class="mb-0">
            <a href="https://www.linkedin.com/in/MichaelSchmidle"
                class="btn btn-light rounded-pill text-muted"><i class="lab la-linkedin-in"></i>&nbsp;LinkedIn</a>
            
            <a href="https://github.com/MichaelSchmidle/"
                class="btn btn-light rounded-pill text-muted"><i class="lab la-github"></i>&nbsp;GitHub</a>
            
            <a href="https://soundcloud.com/michaelschmidle/"
                class="btn btn-light rounded-pill text-muted"><i class="lab la-soundcloud"></i>&nbsp;SoundCloud</a>
            </p>
    </div>
</div>
            </div>
        </div>
    </div>
</section>



<section class="container py-5">
    <div class="yx-heading">
        Recommended Articles
    </div>
    
    
    <div class="row align-items-center">
    <div class="col-md-4 mb-3 mb-md-0 order-md-last">
        
        <a href="/articles/why-agi-might-never-exist/">
            <picture>
                <source media="(min-width: 1200px)"
                    srcset="https://res.cloudinary.com/ypertex/image/upload/ar_1,c_fill,dpr_auto,f_auto,g_auto,q_auto,w_350/816f7fa0-6d86-4d88-9baf-b8cef8ee4531">
                <source media="(min-width: 992px)"
                    srcset="https://res.cloudinary.com/ypertex/image/upload/ar_1,c_fill,dpr_auto,f_auto,g_auto,q_auto,w_290/816f7fa0-6d86-4d88-9baf-b8cef8ee4531">
                <source media="(min-width: 768px)"
                    srcset="https://res.cloudinary.com/ypertex/image/upload/ar_0.75,c_fill,dpr_auto,f_auto,q_auto,w_210/816f7fa0-6d86-4d88-9baf-b8cef8ee4531">
                <source media="(min-width: 576px)"
                    srcset="https://res.cloudinary.com/ypertex/image/upload/ar_2,c_fill,dpr_auto,f_auto,q_auto,w_510/816f7fa0-6d86-4d88-9baf-b8cef8ee4531">
                <img src="https://res.cloudinary.com/ypertex/image/upload/ar_2,c_fill,dpr_auto,f_auto,q_auto,w_545/816f7fa0-6d86-4d88-9baf-b8cef8ee4531" alt=""
                    class="shadow w-100">
            </picture>
        </a>
        
    </div>
    <div class="col-md-8 text-md-right">
        <p class="text-muted mb-2"><small><i
            class="las la-upload"></i>&nbsp;Jan 22, 2025 · <i
            class="las la-stopwatch"></i>&nbsp;8min read</small></p>
<div class="yx-stretched-linkable mb-3">
    <h2>The Vanishing Point—Why AGI Might Never Exist</h2>
    <p>What if AGI (Artificial General Intelligence) is impossible not because we can&rsquo;t achieve it, but because it can&rsquo;t exist as a stable state? A dialogue about processing speed, dimensional transcendence, and why we might be playing Russian roulette with our civilization&rsquo;s future. <a href="/articles/why-agi-might-never-exist/" class="stretched-link">Continue…</a></p>
</div>
<p class="mb-2">
    
    <a href="/tags/ai/" class="badge badge-primary"><i class="las la-hashtag"></i>AI</a>
    
    <a href="/tags/future/" class="badge badge-primary"><i class="las la-hashtag"></i>Future</a>
    
    <a href="/tags/technology/" class="badge badge-primary"><i class="las la-hashtag"></i>Technology</a>
    
</p>

    </div>
</div>

    
    
    <hr>
    
    <div class="row align-items-center">
    <div class="col-md-4 mb-3 mb-md-0">
        
        <a href="/articles/innovating-our-stagnation/">
            <picture>
                <source media="(min-width: 1200px)"
                    srcset="https://res.cloudinary.com/ypertex/image/upload/ar_1,c_fill,dpr_auto,f_auto,g_auto,q_auto,w_350/f26ee4ba-0482-4879-bf70-4f22aa033b58">
                <source media="(min-width: 992px)"
                    srcset="https://res.cloudinary.com/ypertex/image/upload/ar_1,c_fill,dpr_auto,f_auto,g_auto,q_auto,w_290/f26ee4ba-0482-4879-bf70-4f22aa033b58">
                <source media="(min-width: 768px)"
                    srcset="https://res.cloudinary.com/ypertex/image/upload/ar_0.75,c_fill,dpr_auto,f_auto,q_auto,w_210/f26ee4ba-0482-4879-bf70-4f22aa033b58">
                <source media="(min-width: 576px)"
                    srcset="https://res.cloudinary.com/ypertex/image/upload/ar_2,c_fill,dpr_auto,f_auto,q_auto,w_510/f26ee4ba-0482-4879-bf70-4f22aa033b58">
                <img src="https://res.cloudinary.com/ypertex/image/upload/ar_2,c_fill,dpr_auto,f_auto,q_auto,w_545/f26ee4ba-0482-4879-bf70-4f22aa033b58" alt=""
                    class="shadow w-100">
            </picture>
        </a>
        
    </div>
    <div class="col-md-8">
        <p class="text-muted mb-2"><small><i
            class="las la-upload"></i>&nbsp;Mar 8, 2020 · <i
            class="las la-stopwatch"></i>&nbsp;4min read</small></p>
<div class="yx-stretched-linkable mb-3">
    <h2>Are We Innovating Our Stagnation?</h2>
    <p>Today&rsquo;s global challenges require humankind to learn and adapt. Artificial Intelligence will help driving these changes, right?&mdash;Maybe not. <a href="/articles/innovating-our-stagnation/" class="stretched-link">Continue…</a></p>
</div>
<p class="mb-2">
    
    <a href="/tags/ai/" class="badge badge-primary"><i class="las la-hashtag"></i>AI</a>
    
    <a href="/tags/future/" class="badge badge-primary"><i class="las la-hashtag"></i>Future</a>
    
    <a href="/tags/innovation/" class="badge badge-primary"><i class="las la-hashtag"></i>Innovation</a>
    
</p>

    </div>
</div>

    
    
    <hr>
    
    <div class="row align-items-center">
    <div class="col-md-4 mb-3 mb-md-0 order-md-last">
        
        <a href="/articles/humanity-is-expecting-offspring/">
            <picture>
                <source media="(min-width: 1200px)"
                    srcset="https://res.cloudinary.com/ypertex/image/upload/ar_1,c_fill,dpr_auto,f_auto,g_auto,q_auto,w_350/740eae17-92aa-49bb-b76f-1d12939a6997">
                <source media="(min-width: 992px)"
                    srcset="https://res.cloudinary.com/ypertex/image/upload/ar_1,c_fill,dpr_auto,f_auto,g_auto,q_auto,w_290/740eae17-92aa-49bb-b76f-1d12939a6997">
                <source media="(min-width: 768px)"
                    srcset="https://res.cloudinary.com/ypertex/image/upload/ar_0.75,c_fill,dpr_auto,f_auto,q_auto,w_210/740eae17-92aa-49bb-b76f-1d12939a6997">
                <source media="(min-width: 576px)"
                    srcset="https://res.cloudinary.com/ypertex/image/upload/ar_2,c_fill,dpr_auto,f_auto,q_auto,w_510/740eae17-92aa-49bb-b76f-1d12939a6997">
                <img src="https://res.cloudinary.com/ypertex/image/upload/ar_2,c_fill,dpr_auto,f_auto,q_auto,w_545/740eae17-92aa-49bb-b76f-1d12939a6997" alt=""
                    class="shadow w-100">
            </picture>
        </a>
        
    </div>
    <div class="col-md-8 text-md-right">
        <p class="text-muted mb-2"><small><i
            class="las la-upload"></i>&nbsp;Mar 30, 2017 · <i
            class="las la-stopwatch"></i>&nbsp;15min read</small></p>
<div class="yx-stretched-linkable mb-3">
    <h2>Humankind Is Expecting Offspring—Are We Ready?</h2>
    <p>The advent of Artificial General Intelligence is close, leading to all kinds of questions and potential for conflict. How do we make sure that we are ready? <a href="/articles/humanity-is-expecting-offspring/" class="stretched-link">Continue…</a></p>
</div>
<p class="mb-2">
    
    <a href="/tags/ai/" class="badge badge-primary"><i class="las la-hashtag"></i>AI</a>
    
    <a href="/tags/future/" class="badge badge-primary"><i class="las la-hashtag"></i>Future</a>
    
</p>

    </div>
</div>

    
    
    <hr>
    
    <div class="row align-items-center">
    <div class="col-md-4 mb-3 mb-md-0">
        
        <a href="/articles/revolutionizing-decision-making/">
            <picture>
                <source media="(min-width: 1200px)"
                    srcset="https://res.cloudinary.com/ypertex/image/upload/ar_1,c_fill,dpr_auto,f_auto,g_auto,q_auto,w_350/d5feb54a-dc7a-4b08-a840-db6a7f3ef9ff">
                <source media="(min-width: 992px)"
                    srcset="https://res.cloudinary.com/ypertex/image/upload/ar_1,c_fill,dpr_auto,f_auto,g_auto,q_auto,w_290/d5feb54a-dc7a-4b08-a840-db6a7f3ef9ff">
                <source media="(min-width: 768px)"
                    srcset="https://res.cloudinary.com/ypertex/image/upload/ar_0.75,c_fill,dpr_auto,f_auto,q_auto,w_210/d5feb54a-dc7a-4b08-a840-db6a7f3ef9ff">
                <source media="(min-width: 576px)"
                    srcset="https://res.cloudinary.com/ypertex/image/upload/ar_2,c_fill,dpr_auto,f_auto,q_auto,w_510/d5feb54a-dc7a-4b08-a840-db6a7f3ef9ff">
                <img src="https://res.cloudinary.com/ypertex/image/upload/ar_2,c_fill,dpr_auto,f_auto,q_auto,w_545/d5feb54a-dc7a-4b08-a840-db6a7f3ef9ff" alt=""
                    class="shadow w-100">
            </picture>
        </a>
        
    </div>
    <div class="col-md-8">
        <p class="text-muted mb-2"><small><i
            class="las la-upload"></i>&nbsp;Oct 6, 2024 · <i
            class="las la-stopwatch"></i>&nbsp;4min read</small></p>
<div class="yx-stretched-linkable mb-3">
    <h2>Revolutionizing Decision-Making</h2>
    <p>Last year, I shared a simple framework for making better decisions. Little did I know it would spark a journey that led to creating PrioMind, an app that&rsquo;s revolutionizing how we approach choices. Here&rsquo;s the story of how four criteria evolved into a powerful decision-making tool, and what I&rsquo;ve learned along the way. <a href="/articles/revolutionizing-decision-making/" class="stretched-link">Continue…</a></p>
</div>
<p class="mb-2">
    
    <a href="/tags/strategy/" class="badge badge-primary"><i class="las la-hashtag"></i>Strategy</a>
    
    <a href="/tags/innovation/" class="badge badge-primary"><i class="las la-hashtag"></i>Innovation</a>
    
    <a href="/tags/leadership/" class="badge badge-primary"><i class="las la-hashtag"></i>Leadership</a>
    
</p>

    </div>
</div>

    
</section>



    </main>
    <footer class="bg-secondary text-light text-center">
  <div class="container py-5">
    
    <p><small><a href="/privacy/">Privacy Policy</a></small></p>
    <p><a href="/"><svg width="100%" height="100%" viewBox="0 0 440 176" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" xmlns:serif="http://www.serif.com/" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:2;">
    <g transform="matrix(1,0,0,1,-2574,-792)">
        <g id="Unprotected-primary-color-logogram-on-transparent-background" serif:id="Unprotected primary color logogram on transparent background" transform="matrix(1.12719,0,0,0.885774,2612.5,797.543)">
            <rect x="-34.159" y="-6.258" width="390.352" height="198.696" style="fill:none;"/>
            <clipPath id="_clip1">
                <rect x="-34.159" y="-6.258" width="390.352" height="198.696"/>
            </clipPath>
            <g clip-path="url(#_clip1)">
                <g transform="matrix(3.69565,0,0,4.16217,-240.2,-272.956)">
                    <g transform="matrix(0.105625,-6.62507e-18,5.86335e-18,0.119347,45.1899,52.1434)">
                        <path d="M100,500L300,300L100,100L167.274,100C252.258,100 333.761,133.757 393.857,193.846C397.723,197.712 400,199.988 400,199.988L500,99.976L699.976,100L800,200.024L900,100L1100,100L900,300L1100,500L1032.74,500C947.747,500 866.238,466.238 806.141,406.141C802.276,402.276 800,400 800,400L700,500L500,500L700,300L600,200.024L300,500L100,500Z" style="fill:rgb(0,170,255);"/>
                    </g>
                    <g transform="matrix(0.105625,0,0,0.119347,45.1899,40.2116)">
                        <path d="M500,599.976L900,199.976L700,199.953L300,599.976L500,599.976Z" style="fill:rgb(14,17,18);fill-opacity:0.2;"/>
                    </g>
                </g>
            </g>
        </g>
    </g>
</svg>
</a></p>
    <p><small>Copyright © 2017-2025 Michael Schmidle<br>
        Original content released under the <a href="http://creativecommons.org/licenses/by/4.0/">CC BY 4.0 International</a> license</small>
    </p>
  </div>
</footer>
    <script src="https://code.jquery.com/jquery-3.4.1.slim.min.js"
    integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n"
    crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js"
    integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6"
    crossorigin="anonymous"></script>
</body>

</html>