---
title: Innovating Our Own Stagnation?
date: 2020-03-08
authors: [Michael Schmidle]
slug: innovating-our-own-stagnation
tags: [Innovation, Artificial Intelligence]
summary: Today's global challenges require humankind to learn and adapt. Artificial Intelligence will help driving these changes, right?---Maybe not.
cover: https://res.cloudinary.com/ypertex/image/upload/ar_5:3,c_fill,g_auto,q_auto/v1581544571/f26ee4ba-0482-4879-bf70-4f22aa033b58.jpg
---

Today, we celebrate **[International Women's Day](https://www.internationalwomensday.com/) 2020** that promotes the power and value of half the world's population---and how far we still are from giving everyone equal opportunities.

It's an example of what humankind has yet to learn: a lot!

{{<figure src="https://res.cloudinary.com/ypertex/image/upload/ar_5:3,c_fill,g_auto,q_auto,w_740/v1581544571/f26ee4ba-0482-4879-bf70-4f22aa033b58.jpg">}}"An equal world is an enabled world." (Image: [internationalwomensday.com](https://www.internationalwomensday.com/)){{</figure>}}

## So Let's Learn?

Actually, let's **unlearn** first. Since we want to *change* an already existing behavior and not simply add a completely new skill to our repertoire, we first have to forget our current behavior. For example, just to name two:

* How we define roles
* How we award people their opportunities

But how do you do that, selectively forget a behavior? As entire societies at that? A behavior that "successfully" has brought us so far?

Unlearning is tough. Just look at the Blockbusters and Nokias of this world that were extremely successful companies once before they got disrupted. The behaviors that made them so successful in the first place were the same that killed their business in the end. They missed the right time to unlearn.

## So Let's Machine Learn!

One current global trend is the increasing use of Artificial Intelligence to solve all kinds of problems. Based on massive amounts of data, machines learn patterns to understand the world and interact with humans in a meaningful way.

AI is the kind of technology that can have profound social implications. With the potential to replace us all in our jobs, it could free us from arduous labor---or rob us of our purpose of life.

In any case, it could aggravate the fundamental human difficulty to unlearn. As I just wrote: Machines learn based on massive amounts of data. However, data can only be a representation of the past and of a forecast---not of a radically different future. To get to such a future that's different and improved, we'll have to [teach machines how to unlearn](https://www.wired.com/story/the-next-big-privacy-hurdle-teaching-ai-to-forget/), too. How do we achieve that if we as humans already have trouble learning to unlearn?

> Aritficial Intelligence has the power to make our future an optimized and scaled version of our past. Attempts to significantly improve our situation will have to increasingly overcome this power.

All cases of AI known to me are aimed at optimizing and scaling what humans *already* try to do. It's all about exploiting the status quo:

* Recognize objects and emotions
* Translate languages
* Drive cars
* Report on sports results and financial statements
* Etc.

In every case, the AI is supposed to perform the tasks faster, cheaper and more reliably compared to humans.

If humans hired mostly white men for senior positions so far, an AI can do so faster, cheaper and more reliably. But [that's not what we want](https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G), right?

Also, if a justice system is biased, an [AI could optimize and scale that bias](https://www.aclu.org/issues/privacy-technology/surveillance-technologies/ai-and-criminal-justice-devil-data) in a court's automated decision making based on historical data. Combine this with a self-driving car that's [programmed to spare a dog's life at the expense of a criminal](https://www.weforum.org/agenda/2018/10/how-should-autonomous-vehicles-be-programmed)---and every minor, biased court sentence could lead to one's death penalty by car accident.

{{<figure src="https://res.cloudinary.com/ypertex/image/upload/ar_5:3,c_fill,g_auto,q_auto,w_740/v1581544571/e61eeb67-4397-4c82-98c4-5b332bd51be7.jpg">}}A car with autopilot: Tesla Model 3 (Image: [Vlad Tchompalov](https://unsplash.com/@tchompalov)){{</figure>}}

## So... What Now?

If we continue to deploy Artificial Intelligence around the world in all aspects of our lives, it might make it even more difficult for our society to unlearn current, then learn new and improved behaviors.  

If we're not careful, AI might cement the status quo that we actually want to get rid of.

> With AI, we might be innovating our own stagnation.

To avoid such a deadlock, we need to combine the two: We're good at **learning** but suck at **unlearning**. That equally applies to humans and machines, by the way.

How about learning to unlearn, using our existing strength to build a new strength? **Exploring, not just exploiting?** Maybe it'll get easier if we all do it together. Oh, and it just might help you to survive the next disruption, too!

---

## Recommended Reading

* [The Unnatural Ethics of AI Could Be Its Undoing](https://getpocket.com/explore/item/the-unnatural-ethics-of-ai-could-be-its-undoing)